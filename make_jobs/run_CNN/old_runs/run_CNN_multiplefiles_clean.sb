#!/bin/bash --login

########## SBATCH Lines for Resource Request ##########
 
#SBATCH --time=47:59:00             # limit of wall clock time - how long the job will run (same as -t)
#SBATCH --gres=gpu:1                # number of different nodes - could be an exact number or a range of nodes (same as -N)
#SBATCH --mem=150G            # memory required per allocated CPU (or core) - amount of memory (in bytes)
#SBATCH --job-name CNN_clean_multiplefiles      # you can give your job a name for easier identification (same as -J)
#SBATCH --output /mnt/home/micall12/DNN_LE/CNN_multiplefiles_clean.out

########## Command Lines to Run ##########

singularity exec --nv /mnt/research/IceCube/Software/icetray_stable-tensorflow.sif python /mnt/home/micall12/DNN_LE/CNN_LoadMultipleFiles.py --input_files "NuMu_140000_level2.zst_cleaned_lt100_CC_flat_95bins_36034evtperbinall_file0?.transformedinputoutput.hdf5" --name numu_flat_EZ_5_100_CC_cleaned_3600kevents -e 70 --start 210 --model /mnt/home/micall12/DNN_LE/output_plots/numu_flat_EZ_5_100_CC_cleaned_3600kevents/numu_flat_EZ_5_100_CC_cleaned_3600kevents_210epochs_model.hdf5
