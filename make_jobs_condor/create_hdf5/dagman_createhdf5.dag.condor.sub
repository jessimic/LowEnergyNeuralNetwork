# Filename: dagman_createhdf5.dag.condor.sub
# Generated by condor_submit_dag dagman_createhdf5.dag 
universe	= scheduler
executable	= /usr/bin/condor_dagman
getenv		= True
output		= dagman_createhdf5.dag.lib.out
error		= dagman_createhdf5.dag.lib.err
log		= dagman_createhdf5.dag.dagman.log
remove_kill_sig	= SIGUSR1
+OtherJobRemoveRequirements	= "DAGManJobId =?= $(cluster)"
# Note: default on_exit_remove expression:
# ( ExitSignal =?= 11 || (ExitCode =!= UNDEFINED && ExitCode >=0 && ExitCode <= 2))
# attempts to ensure that DAGMan is automatically
# requeued by the schedd if it exits abnormally or
# is killed (e.g., during a reboot).
on_exit_remove	= (ExitSignal =?= 11 || (ExitCode =!= UNDEFINED && ExitCode >=0 && ExitCode <= 2))
copy_to_spool	= False
arguments	= "-p 0 -f -l . -Lockfile dagman_createhdf5.dag.lock -AutoRescue 1 -DoRescueFrom 0 -Dag dagman_createhdf5.dag -Suppress_notification -CsdVersion $CondorVersion:' '8.9.6' 'Mar' '22' '2020' 'BuildID:' '498526' 'PackageID:' '8.9.6-1' '$ -Dagman /usr/bin/condor_dagman"
environment	= _CONDOR_DAGMAN_CONFIG_FILE=/mnt/lfs7/user/jmicallef/LowEnergyNeuralNetwork/make_jobs_condor/create_hdf5/dagman.config;_CONDOR_SCHEDD_ADDRESS_FILE=/var/lib/condor/spool/.schedd_address;_CONDOR_MAX_DAGMAN_LOG=0;_CONDOR_SCHEDD_DAEMON_AD_FILE=/var/lib/condor/spool/.schedd_classad;_CONDOR_DAGMAN_LOG=dagman_createhdf5.dag.dagman.out
queue
